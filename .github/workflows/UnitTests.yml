# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This workflow will install Python dependencies, run tests and lint with a variety of Python versions
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Unit Test

on:
  pull_request:
  push:
    branches: [ "main" ]
  workflow_dispatch:
  schedule:
    # Run the job every 2 hours
    - cron:  '0 */2 * * *'

jobs:
  common:
    strategy:
      fail-fast: False
      matrix:
        device:
        - type: tpu
          name: v4-8
          image_suffix: jax_stable
          attention: flash
        - type: gpu
          name: a100-40gb-4
          image_suffix: gpu_jax_pinned
          attention: dot_product
          container_env:
            XLA_PYTHON_CLIENT_MEM_FRACTION: 0.65
            TF_FORCE_GPU_ALLOW_GROWTH: true
          container_resource_option: "--shm-size 2g --runtime=nvidia --gpus all"
    name: Common test (${{ matrix.device.type }})
    runs-on: ["self-hosted", "${{ matrix.device.type }}", "${{ matrix.device.name }}"]

    container:
      image: gcr.io/tpu-prod-env-multipod/maxtext_${{ matrix.device.image_suffix }}:latest
      volumes: /home/runner/actions-runner/_work/maxtext/maxtext:/deps
      # env:
      #   XLA_PYTHON_CLIENT_MEM_FRACTION: ${{ device.container_env.XLA_PYTHON_CLIENT_MEM_FRACTION }}
      #   TF_FORCE_GPU_ALLOW_GROWTH: ${{ device.container_env.TF_FORCE_GPU_ALLOW_GROWTH }}
      options: ${{ device.container_resource_option }}
    steps:
    - uses: actions/checkout@v3
    - name: Test gsutil installation
      run: which gsutil >/dev/null 2>&1 || { echo >&2 "gsutil is required but not installed. Aborting"; exit 24;}
    - name: Test with pytest
      run: cd MaxText;python3 -m pytest -m "not tpu"
    - name: Test train.py with c4
      run: |
        python3 MaxText/train.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} 
        base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset steps=2 enable_checkpointing=false attention=${{ device.attention }}
    - name: Test train.py with synthetic data
      run: python3 MaxText/train.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset steps=2 enable_checkpointing=false attention=${{ device.attention }} dataset_type=synthetic
    - name: Test train.py with flash attention
      run: python3 MaxText/train.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset steps=2 enable_checkpointing=false attention=cudnn_flash_te
    - name: Test train.py with per_device_batch_size < 1
      run: python3 MaxText/train.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset steps=2 per_device_batch_size=0.25 ici_tensor_parallelism=4 enable_checkpointing=false attention=${{ device.attention }}
    - name: Test decode.py
      run: python3 MaxText/decode.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset steps=2 ici_tensor_parallelism=4 attention=${{ device.attention }} enable_checkpointing=false max_target_length=128 per_device_batch_size=1
    - name: Test decode.py with per_device_batch_size < 1
      run: python3 MaxText/decode.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset steps=2 ici_tensor_parallelism=4 attention=${{ device.attention }} enable_checkpointing=false max_target_length=128 per_device_batch_size=.25
    - name: Test int8_training
      run: python3 MaxText/train.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset quantization=int8 steps=2 enable_checkpointing=false attention=${{ device.attention }}
    - name: Test fp8_training
      run: python3 MaxText/train.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset quantization=fp8 steps=2 enable_checkpointing=false attention=${{ device.attention }}
    - name: Test generate_param_only_checkpoint
      run: bash end_to_end/test_generate_param_only_checkpoint.sh -r runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} -o gs://runner-maxtext-logs -d gs://maxtext-dataset -i 4 -a ${{ device.attention }}
    - name: Test generate_param_only_checkpoint with int8 quantization
      run: bash end_to_end/test_generate_param_only_checkpoint.sh -r runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} -o gs://runner-maxtext-logs -d gs://maxtext-dataset -i 4 -q int8 -a ${{ device.attention }}
    - name: Test grain checkpoint determinism
      run: bash end_to_end/test_checkpointing.sh runner gs://runner-maxtext-logs gs://maxtext-dataset False c4-array_record ${{ device.attention }}
    - name: Test checkpoint compatibility
      run: bash end_to_end/test_checkpoint_compatibility.sh runner gs://runner-maxtext-logs gs://maxtext-dataset ${{ device.attention }}

  tpu:
    strategy:
      fail-fast: false
      matrix:
        device-type: ["v4-8"]
    name: "TPU test (${{ matrix.device-type }})"
    runs-on: ["self-hosted", "tpu", "${{ matrix.device-type }}"]
    container:
      image: gcr.io/tpu-prod-env-multipod/maxtext_jax_stable:latest
      volumes: /home/runner/actions-runner/_work/maxtext/maxtext:/deps
    steps:
    - uses: actions/checkout@v3
    - name: Test with pytest
      run: cd MaxText;python3 -m pytest
    - name: Validate Pedagogical Example, Shmap_collective_matmul
      run: python3 pedagogical_examples/shmap_collective_matmul.py

  gpu:
    strategy:
      fail-fast: false
      matrix:
        device-type: ["a100-40gb-4"]
        build-mode: ["pinned"]
    name: "GPU test (${{ matrix.device-type }}, ${{ matrix.build-mode }})"
    runs-on: ["self-hosted", "gpu", "${{ matrix.device-type }}"]
    container:
      image: gcr.io/tpu-prod-env-multipod/maxtext_gpu_jax_pinned:latest
      volumes: /home/runner/actions-runner/_work/maxtext/maxtext:/deps
      env:
        XLA_PYTHON_CLIENT_MEM_FRACTION: 0.65
        TF_FORCE_GPU_ALLOW_GROWTH: true
      options: "--shm-size 2g --runtime=nvidia --gpus all"
    steps:
    - uses: actions/checkout@v3
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    - name: Test with pytest
      run: cd MaxText;python3 -m pytest -m "not tpu"
    - name: Test train.py with flash attention
      run: python3 MaxText/train.py MaxText/configs/base.yml run_name=runner_$(date +%Y-%m-%d-%H-%M)-${RANDOM} base_output_directory=gs://runner-maxtext-logs dataset_path=gs://maxtext-dataset steps=2 enable_checkpointing=false attention=cudnn_flash_te
